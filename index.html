<!-- 
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="robots" content="index,follow">
    <meta name="keywords" content="Wayne Wu; Wenyan Wu; Tsinghua University; SenseTime Research; WFLW; wider facial landmarks in-the-wild; Face Alignment; Computer Vision; Machine Learning; Multimedia Lab; The Chinese University of Hong Kong; CUHK; 吴文岩; 清华">
    <link rel="author" href="https://wywu.github.io/">
    <title>Wayne Wu's Homepage - CS at Tsinghua University</title>
    <link rel="stylesheet" href="style.css" type="text/css" />
    <link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

</head>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-45959174-3', 'wywu.github.io');
  ga('send', 'pageview');
</script>

<body>
    <div id="container">
        <div id="header">
            <h1><a href="#">Wayne Wu</a></h1>
            <h2>吳文巖</h2>
            <div class="clear"></div>
        </div>
<!--         <div id="nav">
            <ul>
                <li class="start selected"><a href="#">Home</a></li>
                <li><a href="#updates">Updates</a></li>
                <li><a href="#publication">Publication</a></li>
                <li class="end"><a href="#contacts">Contacts</a></li>
            </ul>
        </div> -->
        <div id="body">
            <div id="aboutme">
                <h2>About Me</h2>
                <table class="table-bio">
                    <td class="col-7">
                        <p>I am currently a visiting scholar in <a href="http://mmlab.ie.cuhk.edu.hk/">MMLab</a> Singapore, Nanyang Technological University, supervised by Prof. <a href="http://personal.ie.cuhk.edu.hk/~ccloy/index.html">Chen Change Loy</a>. I am a last year Ph.D candidate in <a href="http://www.bnrist.tsinghua.edu.cn/publish/BNRisten/index.html">BNRist Lab</a>, Department of Computer Science and Technology, Tsinghua University. Also, I am a Researcher at <a href="https://www.sensetime.com/?lang=en-us">SenseTime Research</a>, working closely with <a href="https://scholar.google.com/citations?user=AerkT0YAAAAJ&hl=en">Chen Qian</a> and <a href="https://scholar.google.com/citations?user=F5rVlz0AAAAJ&hl=en">Cheng Li</a>. My research interests lie at the intersection of Computer Vision, Augmented Reality and Machine Learning, especially Generative Model and Facial Animation. I used to work with Prof. <a href="https://scholar.google.com.sg/citations?user=e-4LoEcAAAAJ&hl=en">Zhoujun Li</a> during Sep. 2013 to Jun. 2014.
                    </td>
                    <td class="col-3">
                        <img src="./images/Wayne_Wu.jpg">
                    </td>
                </table>
            </div>

            <div id="news">
                <h2>News</h2>
                <br>
                    <ul>
			<li><font color="ff0000"> <strong><em>We are recruiting interns / full-time researchers in computer vision at SenseTime Research (Beijing/Shanghai/Shenzhen). If you are interested in, please send your CV to my email.</em></strong></font></li>
                   		<br>
			<li>We are organizing <strong><a href="https://competitions.codalab.org/competitions/25228">DeeperForensics Challenge</a></strong> together with <strong><a href="https://sense-human.github.io/">ECCV 2020 SenseHuman Workshop</a></strong>. (2020-08-28)</li>
                        <br>
                        <li>We released <strong><a href="https://github.com/open-mmlab/mmaction2">MMAction2</a></strong>, OpenMMLab's Next Generation Action Understanding Toolbox. (2020-07-10)</li>
                        <br>
                        <li>We released <strong><a href="https://github.com/open-mmlab/mmediting">MMEditing</a></strong>, OpenMMLab Image and Video Editing Toolbox. (2020-07-10)</li>
                        <br>
			<li>The <strong><a href="https://github.com/EndlessSora/DeeperForensics-1.0">DeeperForensics-1.0 Dataset</a></strong> is publicly available now. (2020-05-21)</li>
                        <br>
                        <li>The <strong><a href="https://github.com/wywu/ReenactGAN">Code and Model </a></strong> of ReenactGAN are publicly available now. (2019-10-07)</li>
                        <br>
                        <li><strong><a>5 papers</a></strong> got accepted by CVPR/ICCV/ICLR in 2019. (2019-07-23)</li>       
    			<br>
                        <li>The <strong><a href="https://github.com/wywu/LAB.git">Testing Code and Model</a></strong> of LAB are publicly available now. (2018-07-26)</li>
                        <br>
                        <li>The <strong><a href="./projects/LAB/WFLW.html">Wider Facial Landmarks in-the-wild Dataset</a></strong> (WFLW) is publicly available now. (2018-07-15)</li>
                        <br>
                        <li><strong><a>3 papers</a></strong> got accepted by CVPR/ECCV/NeurIPS in 2018. (2018-07-10)</li>       
    			<br>
                        <li>Our team won the <strong><a href="https://www.vision.ee.ethz.ch/webvision/workshop.html">WebVision Challenge 2018</a></strong> as first runner-up. (2018-06-20)</li>
                        <br>
<!--                         <li>Our paper <strong><a href="./supports/DVLN_paper.pdf">DVLN</a></strong> is accepted to CVPR 2017 Workshop. (2017-05-10)</li>
                        <br> -->
                    </ul>
            </div>


		
            <div id="preprint">
                <h2>Preprint</h2>
                <table class="table-pub">



		    <tr>
                        <td class="col-3"><a href=""><img src="images/EBT.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Everybody’s Talkin’: Let Me Talk as You Want</h6><br>
                                Linsen Song, <b>Wayne Wu</b>, Chen Qian, Ran He, Chen Change Loy.<br>
                                <i>Technical report, 2020.</i><br><br>
                                [<a href="https://arxiv.org/abs/2001.05201">Paper</a>]&nbsp;[<a href="./projects/EBT/EBT.html">Project Page</a>]
                            </div>
                        </td>
                    </tr>
			

		    <tr>
                        <td class="col-3"><a href=""><img src="images/TAM.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>TAM: Temporal Adaptive Module for Video Recognition</h6><br>
                                Zhaoyang Liu, Limin Wang, <b>Wayne Wu</b>, Chen Qian, Tong Lu.<br>
                                <i>Technical report, 2020.</i><br><br>
                                [<a href="https://arxiv.org/abs/2005.06803">Paper</a>]&nbsp;[<a href="https://github.com/liu-zhy/TANet">Code and Model</a>]
                            </div>
                        </td>
                    </tr>

                </table>
            </div>

            <div id="publication">
                <h2>Selected Publications</h2>
                <table class="table-pub">

                    <tr>
                        <td class="col-3"><a href=""><img src="images/MEAD.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>MEAD: A Large-scale Audio-visual Dataset for Emotional Talking Face Generation</h6><br>
                                <span>Kaisiyuan Wang&#42;, <span>Qianyi Wu&#42;, <span>Linsen Song&#42;, Zhuoqian Yang, <b>Wayne Wu</b>, Chen Qian, Ran He, Yu Qiao, Chen Change Loy.<br>
                                <i>European Conference on Computer Vision (ECCV), 2020.</i><br><br>
                                (&#42; indicates equal contribution.)<br><br>
                                [<a href="">Paper</a>]&nbsp;[<a href="https://wywu.github.io/projects/MEAD/MEAD.html">Project Page</a>]
                                &nbsp;[<a href="">Code and Model</a>]
                            </div>
                        </td>
                    </tr>
				    
                    <tr>
                        <td class="col-3"><a href=""><img src="images/BCM.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Bi-directional Cross-Modality Feature Propagation with Separation-and-Aggregation Gate for RGB-D Semantic Segmentation</h6><br>
                                Xiaokang Chen, Kwan-Yee Lin, Jingbo Wang, <b>Wayne Wu</b>, Chen Qian, Hongsheng Li, Gang Zeng.<br>
                                <i>European Conference on Computer Vision (ECCV), 2020.</i><br><br>
                                [<a href="">Paper</a>]
                            </div>
                        </td>
                    </tr>
			
                    <tr>
                        <td class="col-3"><a href="https://yzhq97.github.io/transmomo"><img src="images/TransMoMo.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>TransMoMo: Invariance-Driven Unsupervised Video Motion Retargeting</h6><br>
                                <span>Zhuoqian Yang&#42;, <span>Wentao Zhu&#42;, <span><b>Wayne Wu</b>&#42;, Chen Qian, Qiang Zhou, Bolei Zhou, Chen Change Loy.<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.</i><br><br>
                                (&#42; indicates equal contribution.)<br><br>
                                [<a href="http://arxiv.org/abs/2003.14401">Paper</a>]&nbsp;[<a href="https://yzhq97.github.io/transmomo">Project Page</a>]
                                &nbsp;[<a href="https://github.com/yzhq97/transmomo.pytorch">Code and Model</a>]
                            </div>
                        </td>
                    </tr>
				    
                    <tr>
                        <td class="col-3"><a href=""><img src="images/DeeperForensics.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>DeeperForensics-1.0: A Large-Scale Dataset for Real-World Face Forgery Detection</h6><br>
                                Liming Jiang, Ren Li, <b>Wayne Wu</b>, Chen Qian, Chen Change Loy.<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.</i><br><br>
                                [<a href="https://arxiv.org/abs/2001.03024">Paper</a>]&nbsp;[<a href="https://liming-jiang.com/projects/DrF1/DrF1.html">Project Page</a>]
                                &nbsp;[<a href="https://github.com/EndlessSora/DeeperForensics-1.0">Code and Model</a>]
                            </div>
                        </td>
                    </tr> 

				    

				    
				    
				    
				    
                    <tr>
                        <td class="col-3"><a href=""><img src="images/AggViaSep.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Aggregation via Separation: Boosting Facial Landmark Detector with Semi-Supervised Style Translation</h6><br>
                                Shengju Qian, Keqiang Sun, <b>Wayne Wu</b>, Chen Qian, Jiaya Jia.<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2019.</i><br><br>
                                [<a href="https://arxiv.org/pdf/1908.06440.pdf">Paper</a>]&nbsp;[<a href="https://github.com/TheSouthFrog/stylealign">Code and Model</a>]
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-3"><a href=""><img src="images/MakeAFace.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Make a Face: Towards Arbitrary High Fidelity Face Manipulation</h6><br>
                                Shengju Qian, Kwan-Yee Lin, <b>Wayne Wu</b>, Yangxiaokang Liu, Quan Wang, Fumin Shen, Chen Qian, Ran He.<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2019.</i><br><br>
                                [<a href="https://arxiv.org/abs/1908.07191">Paper</a>]
                            </div>
                        </td>
                    </tr>


                    <tr>
                        <td class="col-3"><a href=""><img src="images/FAB.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>FAB: A Robust Facial Landmark Detection Framework for Motion-Blurred Videos</h6><br>
                                Keqiang Sun, <b>Wayne Wu</b>, Tinghao Liu, Shuo Yang, Quan Wang, Qiang Zhou, Zuochang Ye, Chen Qian.<br>
                                <i>IEEE International Conference on Computer Vision (ICCV), 2019.</i><br><br>
                                [<a href="https://keqiangsun.github.io/projects/FAB/support/FAB.pdf">Paper</a>]&nbsp;[<a href="https://keqiangsun.github.io/projects/FAB/">Project Page</a>]
                                &nbsp;[<a href="https://github.com/keqiangsun/FAB">Code and Model</a>]
                            </div>
                        </td>
                    </tr>




                    <tr>
                        <td class="col-3"><a href="./projects/TGaGa/TGaGa.html"><img src="images/TGaGa.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>TransGaGa: Geometry-Aware Unsupervised Image-to-Image Translation</h6><br>
                                <b>Wayne Wu</b>, Kaidi Cao, Cheng Li, Chen Qian, Chen Change Loy.<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2019.</i><br><br>
                                [<a href="https://arxiv.org/pdf/1904.09571.pdf">Paper</a>]&nbsp;[<a href="./projects/TGaGa/TGaGa.html">Project Page</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href=""><img src="images/Disentangling.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Disentangling Content and Style via Unsupervised Geometry Distillation</h6><br>
                                <b>Wayne Wu</b>, Kaidi Cao, Cheng Li, Chen Qian, Chen Change Loy.<br>
                                <i>International Conference on Learning Representations (ICLR) Workshop, 2019.</i><br><br>
                                [<a href="https://arxiv.org/abs/1905.04538">Paper</a>]&nbsp;[<a href="">Project Page</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href="./projects/ReenactGAN/ReenactGAN.html"><img src="images/ReenactGAN.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>ReenactGAN: Learning to Reenact Faces via Boundary Transfer</h6><br>
                                <span><b>Wayne Wu</b>&#42;, <span>Yunxuan Zhang&#42;, Cheng Li, Chen Qian, Chen Change Loy.<br>
                                <i>European Conference on Computer Vision (ECCV), 2018.</i><br>
                                (&#42; indicates equal contribution.)<br><br>
                                [<a href="./projects/ReenactGAN//support/ReenactGAN.pdf">Paper</a>]&nbsp;[<a href="./projects/ReenactGAN/ReenactGAN.html">Project Page</a>]
                                &nbsp;[<a href="https://github.com/wywu/ReenactGAN">Code and Model</a>]
                            </div>
                        </td>
                    </tr>

                    <tr>
                        <td class="col-3"><a href="./projects/LAB/LAB.html"><img src="images/LAB.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Look at Boundary: A Boundary-Aware Face Alignment Algorithm</h6><br>
                                <b>Wayne Wu</b>, Chen Qian, Shuo Yang, Quan Wang, Yici Cai, Qiang Zhou.<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2018.</i><br><br>
                                [<a href="./support/LAB.pdf">Paper</a>]&nbsp;[<a href="./projects/LAB/LAB.html">Project Page</a>]
                                &nbsp;[<a href="https://github.com/wywu/LAB">Code and Model</a>]
                            </div>
                        </td>
                    </tr>

<!--                     <tr>
                        <td class="col-3"><a href=""><img src="images/VariationAlignment.png"></a></td>
                        <td>
                            <div class="pub-info">
                                <h6>Leveraging Intra and Inter-Dataset Variations for Robust Face Alignment</h6><br>
                                <b>Wayne Wu</b>, Shuo Yang.<br>
                                <i>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop, 2017.</i> <br><br>
                                [<a href="./supports/DVLN_paper.pdf">Paper</a>]&nbsp;[<a href="">Project Page</a>]
                            </div>
                        </td>
                    </tr> -->

                </table>
            </div>
            <div id="academic_services">
                <h2>Academic Services</h2>
                <ul>
                    <li>Reviewer for CVPR, ICCV, ECCV, NeurIPS, AAAI</li>
		    <li>Organizer for <a href="https://sense-human.github.io/">ECCV'20 Workshop on Sensing, Understanding and Synthesizing Humans</a></li>
		    <li>Organizer for <a href="http://openaccess.thecvf.com/ICCV2019_workshops/ICCV2019_SDL-CV.py">ICCV'19 Workshop on Statistical Deep Learning for Computer Vision</a></li>
                </ul>
            </div>
            <div id="teaching">
                <h2>Teaching</h2>
                <ul>
                    <li>2017, Spring. Numrical Analysis, THU</li>
                    <li>2016, Spring. Combinatorial Mathematics, THU</li>
                    <li>2014, Spring. Discrete Mathematics, BUAA</li>
                </ul>
            </div>
            <div id="teaching">
                <h2>Selected Honors and Awards</h2>
                <ul>
					<li>Excellent Undergraduate Student in Beijing, 2015</li>
                	<li>Outstanding Undergraduate Thesis, 2015</li>
                    <li>National Scholarship (top 1%), 2014.</li>
                </ul>
            </div>
            <div id="contacts">
                <h2>Contacts</h2>
                <i class="fa fa-envelope"></i> wuwenyan0503 [at] gmail.com
            </div>
            <div class="col-md-3 text-center">
    		<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=QShZBFi6L24FTeLDmu6HjMg_YuX8fOPHLBDJgIWM_so&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>
	    </div>

        </div>
        <div class="clear"></div>
    </div>

<!--     <div id="footer">
        <div class="footer-bottom">
            <p>Style modified from <a href="http://zypopwebtemplates.com/">ZyPOP</a></p>
        </div>
    </div> -->




	  

</body>

</html>


<!-- Asynchronous Google Analytics snippet -->
<!-- <script>
  var _gaq = _gaq || [];
  var pluginUrl =
 '//www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'dbyll']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>


<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=QShZBFi6L24FTeLDmu6HjMg_YuX8fOPHLBDJgIWM_so&cl=ffffff&w=a"></script> -->
 -->
