
<!DOCTYPE html>

<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
	body {
		font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
		font-weight:300;
		font-size:18px;
		margin-left: auto;
		margin-right: auto;
		width: 1100px;
	}

	h1 {
		font-weight:300;
	}

	.disclaimerbox {
		background-color: #eee;
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
		padding: 20px;
	}

	video.header-vid {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.header-img {
		height: 140px;
		border: 1px solid black;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	img.rounded {
		border: 1px solid #eeeeee;
		border-radius: 10px ;
		-moz-border-radius: 10px ;
		-webkit-border-radius: 10px ;
	}

	a:link,a:visited
	{
		color: #1367a7;
		text-decoration: none;
	}
	a:hover {
		color: #208799;
	}

	td.dl-link {
		height: 160px;
		text-align: center;
		font-size: 22px;
	}

	.layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
		        15px 15px 0 0px #fff, /* The fourth layer */
		        15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
		        20px 20px 0 0px #fff, /* The fifth layer */
		        20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
		        25px 25px 0 0px #fff, /* The fifth layer */
		        25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
		margin-left: 10px;
		margin-right: 45px;
	}


	.layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
		box-shadow:
		        0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
		        5px 5px 0 0px #fff, /* The second layer */
		        5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
		        10px 10px 0 0px #fff, /* The third layer */
		        10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
		margin-top: 5px;
		margin-left: 10px;
		margin-right: 30px;
		margin-bottom: 5px;
	}

	.vert-cent {
		position: relative;
	    top: 50%;
	    transform: translateY(-50%);
	}

	hr
	{
		border: 0;
		height: 1.5px;
		background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
	}
</style>

<html>
  <head>
		<title>Everything’s Talkin’: Pareidolia Face Reenactment</title>
  </head>

  <body>
    <br>
    <center>
    <span style="font-size:30px">Everything’s Talkin’: Pareidolia Face Reenactment</span>
	</center>

	<br>


  	<table align=center width=900px>
  	 <tr>
		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a>Linsen Song</a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="http://wywu.github.io">Wayne Wu</a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="https://scholar.google.com.hk/citations?user=4A1xYQwAAAAJ&hl=zh-CN">Chaoyou Fu</a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="https://scholar.google.com/citations?user=AerkT0YAAAAJ&hl=en">Chen Qian</a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="http://personal.ie.cuhk.edu.hk/~ccloy/">Chen Change Loy</a></span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:18px"><a href="https://scholar.google.com/citations?user=ayrg9AUAAAAJ&hl=en">Ran He</a></span>
		</center>
		</td>

	 </tr>
	</table>

	<br>
	
	<table align=center width=900px>
  	 <tr>
		<td align=center width=80px>
		<center>
		<span style="font-size:20px">NLPR & CRIPAC, CASIA</span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:20px">SenseTime Research</span>
		</center>
		</td>

		<td align=center width=80px>
		<center>
		<span style="font-size:20px">S-Lab, Nanyang Technological University</span>
		</center>
		</td>

	 </tr>
	</table>

	<br>



     
  		  <br>
  		  <table align=center width=900px>
  			  <tr>
  	              <td width=900px>
  					<center>
  	                	<a href="./support/ETT.png"><img src = "./support/ETT.png" height="400px"></img></href></a><br>
					</center>
  	              </td>
  	          </tr>
  		  </table>

      	  <br>
      	  <p style="text-align:justify">
				We present a new application direction named Pareidolia Face Reenactment, which is defined as animating a static illusory face to move in tandem with a human face in the video. For the large differences between pareidolia face reenactment and traditional human face reenactment, two main challenges are introduced, i.e., shape variance and texture variance. In this work, we propose a novel Parametric Unsupervised Reenactment Algorithm to tackle these two challenges. Specifically, we propose to decompose the reenactment into three catenate processes: shape modeling, motion transfer and texture synthesis. With the decomposition, we introduce three crucial components, i.e., Parametric Shape Modeling, Expansionary Motion Transfer and Unsupervised Texture Synthesizer, to overcome the problems brought by the remarkably variances on pareidolia faces. Extensive experiments show the superior performance of our method both qualitatively and quantitatively.
      	  </p>
  		  <br><br>
		  <hr>
		 <!-- <table align=center width=550px> -->
  		  <table align=center width=1100>
	 		<center><h1>Paper</h1></center>
  			  <tr>
  	              <!-- <td width=300px align=left> -->
  	              <!-- <a href="http://arxiv.org/pdf/1603.08511.pdf"> -->
				  <!-- <td><a href="#"><img class="layered-paper-big" style="height:175px" src="./resources/images/paper.png"/></a></td> -->
				  <td><a href="https://arxiv.org/pdf/1904.09571.pdf"><img style="height:180px" src="./support/paper.png"/></a></td>
				  <td><span style="font-size:14pt">Everything’s Talkin’: Pareidolia Face Reenactment<br><br>
                          <i>Linsen Song*, Wayne Wu*, Chaoyou Fu, Chen Qian. Chen Change Loy, Ran He</i><br><br>
				  Computer Vision and Pattern Recognition, CVPR 2021. <br>
				  </td>
  	              </td>
              </tr>
  		  </table>
		  <br>

		  <table align=center width=400px>
			  <tr>
				  <td><span style="font-size:14pt"><center>
				  	<a href="./support/ETT.pdf">[PDF]</a>
  	              </center></td>

				  <td><span style="font-size:14pt"><center>
				  	<a href="./support/ETT-supp.pdf">[Appendix]</a>
  	              </center></td>
<!-- 
				  <td><span style="font-size:14pt"><center>
				  	<a href="./support/ETT.pptx">[Poster]</a>
  	              </center></td> -->

				  <td><span style="font-size:14pt"><center>
				  	<a href="https://github.com/Linsen13/EverythingTalking">[Code]</a>
  	              </center></td>


				  <td><span style="font-size:14pt"><center>
				  	<a href="./support/ETT_bibtex.txt">[Bibtex]</a>
  	              </center></td>


              </tr>
  		  </table>
		  	<br>

  		  	<hr>

<!--   		  <table align=center width=1100>
	 		<center><h1>Data (coming soon)</h1></center>
	 		<center>
		   	<div>
				<img src="./support/dog.png" height="170" width=170>
				<img src="./support/cat.jpg" height="170" width=170>
				<img src="./support/horse.jpg" height="170" width=170>
				<img src="./support/giraffe.jpg" height="170" width=170>
				<img src="./support/car.jpg" height="170" width=170>
				<img src="./support/bus.jpg" height="170" width=170>
		 	</div>
		 	</center>
			<br>
			<p class="text-justify">
				We collect a large unpaired image-to-image translation dataset of 10 different categories with large geometry variations, i.e., human-face, cat-face, dog-face, horse, giraffe, cow, lion, bird, bus and car. In average, each dataset has 4500 images for training and 500 images for testing. Each image is center cropped and resized to the same resolution as 256*256.
			</p>
		   	<div>
				<center><a href="" class="btn btn-outline-secondary">[Download]</a></center>
		   	</div>
  		  </table>
		  <br> -->


			<center><h1>Video</h1>

			<table align=center width=800px>
				<tr height="300px">
					<td valign="top" width=500px>
					<center>
					<iframe width="560" height="315" src="https://www.youtube.com/embed/lVYZ3IAVM_U" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
					</center>
					</td>
				</tr>
			</table>
			</center>
		<br>


  		  <hr>



<!--   		  <table align=center width=1100px>
  			  <tr>
  	              <td>
  					<left>
	  		  <center><h1>Acknowledgements</h1></center>
	  		  This research was conducted in collaboration with SenseTime. This work is partially funded by Beijing Natural Science Foundation (Grant No. JQ18017), Youth Inno- vation Promotion Association CAS (Grant No. Y201929), and National Natural Science Foundation of China (Grant No. U20A20223). This work is supported by A*STAR through the Industry Alignment Fund - Industry Collabo- ration Projects Grant.</a>
			</left>
		</td>
		</tr> -->
		</table>


		<br><br>
</body>
</html>
