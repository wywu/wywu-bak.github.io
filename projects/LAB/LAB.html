
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0059)http://personal.ie.cuhk.edu.hk/~ys014/projects/Faceness/Faceness/ -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>From Facial Parts Responses to Face Detection: A Deep Learning Approach</title>

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="description" content="In this paper, we propose a novel deep convolutional network (DCN) that achieves outstanding performance on FDDB, PASCAL Face, and AFW. Specifically, our method achieves a high recall rate of 90.99% on the challenging FDDB benchmark, outperforming the state-of-the-art method by a large margin of 2.91%. Importantly, we consider finding faces from a new perspective through scoring facial parts responses by their spatial structure and arrangement. The scoring mechanism is carefully formulated considering challenging cases where faces are only partially visible. This consideration allows our network to detect faces under severe occlusion and unconstrained pose variation, which are the main difficulty and bottleneck of most existing face detection approaches. We show that despite the use of DCN, our network can achieve practical runtime speed.">
<meta name="keywords" content="face detection; face attributes; faceness; deep learning; Convolutional network; computer vision;">
<link rel="author" href="personal.ie.cuhk.edu.hk/~ys014/">

<!-- Fonts and stuff -->
<link href="./support/css" rel="stylesheet" type="text/css">
<link rel="stylesheet" type="text/css" href="./support/project.css" media="screen">
<link rel="stylesheet" type="text/css" media="screen" href="./support/iconize.css">
<script async="" src="./support/prettify.js"></script>


</head>

<body>
  <div id="content">
    <div id="content-inner">
      
      <div class="section head">
	<h1>From Facial Parts Responses to Face Detection: A Deep Learning Approach</h1>

	<div class="authors">
	  <a href="http://shuoyang1213.me">Shuo Yang</a>&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~pluo/">Ping Luo</a>&nbsp;&nbsp;
	  <a href="http://personal.ie.cuhk.edu.hk/~ccloy/" >Chen Change Loy</a>&nbsp;&nbsp;
	  <a href="http://www.ie.cuhk.edu.hk/people/xotang.shtml">Xiaoou Tang</a>
	</div>

	<div class="affiliations">
	  <a href="http://mmlab.ie.cuhk.edu.hk/">Multimedia Laboratory, </a>
	  <a href="http://www.ie.cuhk.edu.hk/">Department of Information Engineering, </a>
	  <a href="www.cuhk.edu.hk">The Chinese University of Hong Kong</a>
	</div>

	<div class="venue">International Conference on Computer Vision (<a href="http://pamitc.org/iccv15/" target="_blank">ICCV</a>) 2015, Santiago, Chile</div>
      </div>

      
      <center><img src="./support/index.png" border="0" width="85%"></center>
      <div class="section abstract">
	<h2>Abstract</h2>
	<p>
In this paper, we propose a novel deep convolutional network (DCN) that achieves outstanding performance on
FDDB, PASCAL Face, and AFW. Specifically, our method achieves a high recall rate of 90.99% on the challenging FDDB benchmark, outperforming the state-of-the-art method by a large margin of 2.91%. Importantly, we consider finding faces from a new perspective through scoring facial parts responses by their spatial structure and arrangement. The scoring mechanism is carefully formulated considering challenging cases where faces are only partially visible. This consideration allows our network to detect
faces under severe occlusion and unconstrained pose variation, which are the main difficulty and bottleneck of most existing face detection approaches. We show that despite the use of DCN, our network can achieve practical runtime speed.
	</p>
      </div>
<div class="section downloads">
	<h2>Demo</h2><center>
      	<iframe width="420" height="315" src="https://www.youtube.com/embed/IMPjPQSb9g8" frameborder="0" allowfullscreen></iframe>
      </div></center>
      <div class="section downloads">
	<h2>Downloads</h2>
	<center>
	  <ul>
        <li class="grid">
	      <div class="griditem">
		<a href="./support/ICCV15.pdf" target="_blank" class="imageLink"><img src="./support/PDF_thumb.png"></a><br><a href="./support/paper.pdf">Paper and Supplementary</a>
		</div>
	      </li>
	    <li class="grid">
	      <div class="griditem">
		<a href="./support/faceness_prediction.zip" target="_blank" class="imageLink"><img src="./support/faceness_afw_pascal.jpg"></a><br><a href="./support/faceness_prediction.zip" target="_blank">AFW and PASCAL prediction</a>
		</div>
	      </li>
	    <li class="grid">
	      <div class="griditem">
		<img src="./support/dataset.png"></a><br><a href="http://personal.ie.cuhk.edu.hk/~lz013/projects/CelebA.html" target="_blank">CelebFaces Attributes Dataset</a>
		</div>
	      </li>
	    <li class="grid">
	      <div class="griditem">
		<img src="./support/code.png"></a><br><a href="./support/downloadinstruct.txt" target="_blank">Download Instruction</a>
		</div>
	      </li>
	    </ul>
	    </center>
	    </div>
	    


<br>
 <div class="section list">
	<h2>Citation</h2>
	
	<div class="section bibtex">
	  <pre>@inproceedings{yang2015faceness,
 author = {Shuo Yang, Ping Luo, Chen Change Loy, and Xiaoou Tang},
 title = {From Facial Parts Responses to Face Detection: A Deep Learning Approach},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = December,
 year = {2015}
} 
	</pre>
	  </div>
      </div>

     <div class="section contact">
	<h2>Contact</h2>
	Shuo Yang<br><a href="mailto:shuoyang.1213@gmail.com">shuoyang.1213@gmail.com</a>
      </div>
    </div>
  </div>




</body></html>